








	
		
		<div id="session_1187" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=1187" class="openInPopup">
					
						<span class="abbreviation">BDT101 - </span>
					
					<span class="title">Big Data 'State of the Union'</span>
				</a>
				
					<span class="abstract">Big Data is more than petabytes and capacity. It is the opportunity to use data to your advantage to make smart decisions that increase productivity and grow your business. In this session, you'll learn about the latest advancements in data analytics, databases, storage, and high performance computing (HPC) &nbsp;at AWS and discover how to put data to work in your own organization.</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Paul Duffy &ndash; Principal Product Manager with Amazon Web Services<br/>Scott Hagedorn &ndash; CEO with Annalect<br/>Lisa Green &ndash; Director with Common Crawl<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 1187);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(1187, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_1182" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=1182" class="openInPopup">
					
						<span class="abbreviation">BDT102 - </span>
					
					<span class="title">Small Steps in Visual Analytics for NASA's Big Data</span>
				</a>
				
					<span class="abstract">Exploring the cosmos for the better half of a century has generated voluminous stores of varied data. While this data was collected remotely, strides have been made back on earthly clouds that can now elastically store, visually describe and analyze these volumes of data. As the space agency explores ambitious new missions, JPL is taking small steps to unleash these cloud tools on our data that visually educate and enable our engineers to best tackle our future with a data driven understanding of the present. This talk will discuss how JPL is using cloud based visual analytics to resolve mysteries whose questions&nbsp;and answers lay hidden in our data. Usage of Amazon&nbsp;DynamoDB, Amazon S3, Amazon Redshift, Amazon Glacier, Amazon EC2, Amazon EMR, AWS GovCloud and a variety of visual descriptive methods with real examples will be included.</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Robert Witoff &ndash; Data Scientist with NASA JPL<br/>Tom Soderstrom &ndash; IT CTO with JPL<br/>Tom Soderstrom &ndash; IT Chief Technology Officer with NASA<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 1182);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(1182, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_2020" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=2020" class="openInPopup">
					
						<span class="abbreviation">BDT103 - </span>
					
					<span class="title">New Launch: Introducing Amazon Kinesis: The New AWS Service for Real-time Processing of Streaming Big Data</span>
				</a>
				
					<span class="abstract">This presentation will introduce Kinesis, the new AWS service for real-time streaming big data ingestion and processing.
We&rsquo;ll provide an overview of the key scenarios and business use cases suitable for real-time processing, and discuss how AWS designed Amazon Kinesis to help customers shift from a traditional batch-oriented processing of data to a continual real-time processing model. We&rsquo;ll provide an overview of the key concepts, attributes, APIs and features of the service, and discuss building a Kinesis-enabled application for real-time processing. We&rsquo;ll also contrast with other approaches for streaming data ingestion and processing. Finally, we&rsquo;ll discuss how Kinesis fits as part of a larger big data infrastructure on AWS, including S3, DynamoDB, EMR, and Redshift.</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Ryan Waite &ndash; General Manager, Data Services with Amazon Web Services<br/>Aditya Krishnan &ndash; Senior Product Manager with Amazon Web Services<br/>Marvin Theimer &ndash; Vice President, Distinguished Engineer with Amazon Web Services<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 2020);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(2020, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_1374" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=1374" class="openInPopup">
					
						<span class="abbreviation">BDT203 - </span>
					
					<span class="title">Building Your Own Web Analytics Service with node.js, Amazon DynamoDB, and Amazon EMR</span>
				</a>
				
					<span class="abstract">Want to learn how to build your own Google Analytics? Learn how to build a scalable architecture using node.js, Amazon DynamoDB, and Amazon EMR. This architecture is used by ScribbleLive to track billions of engagement minutes per month. In this session, we go over the code in node.js, how to store the data in Amazon DynamoDB, and how to roll-up the data using Hadoop and Hive.&nbsp; Attend this session to learn how to move data quickly at any scale as well as how to use genomic analysis tools and pipelines for next generation sequencers using Globus on AWS.</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Jonathan Keebler &ndash; Founder, Chief Technology Officer with ScribbleLive<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 1374);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(1374, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_1695" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=1695" class="openInPopup">
					
						<span class="abbreviation">BDT204 - </span>
					
					<span class="title">GraphLab: Large-Scale Machine Learning on Graphs</span>
				</a>
				
					<span class="abstract">GraphLab is like Hadoop for graphs in that it enables users to easily express and execute machine learning algorithms on massive graphs. In this session, we illustrate how GraphLab leverages Amazon EC2 and advances in graph representation, asynchronous communication, and scheduling to achieve orders-of-magnitude performance gains over systems like Hadoop on real-world data.</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Joseph Gonzalez &ndash; Co-Founder with GraphLab<br/>Carlos Guestrin &ndash; CEO and Founder with GraphLab<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 1695);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(1695, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_1704" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=1704" class="openInPopup">
					
						<span class="abbreviation">BDT205 - </span>
					
					<span class="title">An MPI-IO Cloud Cluster Bioinformatics Summer Project</span>
				</a>
				
					<span class="abstract">Researchers at Clemson University assigned a student summer intern to explore bioinformatics cloud solutions that leverage MPI, the OrangeFS parallel file system, AWS CloudFormation templates, and a Cluster Scheduler. The result was an AWS cluster that runs bioinformatics code optimized using MPI-IO. We give an overview of the process and show how easy it is to create clusters in AWS.</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Dougal Ballantyne &ndash; Solutions Architect with Amazon Web Services<br/>Boyd Wilson &ndash; Executive with Omnibond<br/>Brandon Posey &ndash; Research Student with Marshall University / Clemson University<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 1704);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(1704, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_1200" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=1200" class="openInPopup">
					
						<span class="abbreviation">BDT206 - </span>
					
					<span class="title">Consumer Analytics in Real Time: How InfoScout Tracks Purchase Behavior with Mechanical Turk</span>
				</a>
				
					<span class="abstract">Understanding the factors that drive consumer purchase behavior make brands better marketers. &nbsp;In this session, join the Vice President of Mechanical Turk to explore how retail businesses are marrying human judgment with large scale data analytics without sacrificing efficiency or scalability.&nbsp; We&rsquo;ll highlight real world examples and introduce Jon Brelig, CTO of InfoScout, to explore how his company is leveraging&nbsp;a combination of automated methods and Mechanical Turk to build out a real-world analytics solution relied upon by brands, such as P&G, Unilever, and General Mills. By extracting item-level purchase data from more than 40,000 consumer receipt images each day and associating it with specific products, brands, user surveys and other digital marketing signals, Infoscout is able to rapidly gauge changes in consumer behavior and market share with remarkable granularity</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Sharon Chiarella &ndash; Vice President with Amazon Web Services<br/>Jon Brelig &ndash; Co-Founder,  CTO with InfoScout<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 1200);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(1200, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_2254" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=2254" class="openInPopup">
					
						<span class="abbreviation">BDT207 - </span>
					
					<span class="title">Orchestrating Big Data Integration and Analytics Data Flows with AWS Data Pipeline</span>
				</a>
				
					<span class="abstract">AWS offers many data services, each optimized for a specific set of structure, size, latency, and concurrency requirements. &nbsp;Making the best use of all specialized services has historically required custom, error-prone data transformation and transport. &nbsp;Now, users can use the AWS Data Pipeline service to orchestrate data flows between Amazon S3, Amazon RDS, Amazon DynamoDB, Amazon Redshift, and on-premise data stores, seamlessly and efficiently applying EC2 instances and EMR clusters to process and transform data. &nbsp;In this session, we demonstrate how you can use AWS Data Pipeline to coordinate your Big Data workflows, applying the optimal data storage technology to each part of your data integration architecture. &nbsp;Swipely's Head of Engineering shows how Swipely uses AWS Data Pipeline to build batch analytics, backfilling all their data, while using resources efficiently. &nbsp;Consequently, Swipely launches novel product features with less development time and less operational complexity. With AWS Data Pipeline, it's easier to reap the benefits of Big Data technology.</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Jon Einkauf &ndash; Senior Product Manager with Amazon Web Services<br/>Anthony Accardi &ndash; Head of Engineering with Swipely<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 2254);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(2254, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_2356" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=2356" class="openInPopup">
					
						<span class="abbreviation">BDT208 - </span>
					
					<span class="title">How the Weather Company Monetizes Weather, the Original Big Data Challenge</span>
				</a>
				
					<span class="abstract">(Presented by Basho) This session will discuss the transformation of the most widely distributed cable TV network in the United States, building on one of the world's most visited digital properties, to create a world class Big Data platform.
Architects, CTOs, CIOs, IT Director, and development managers will learn how to run highly scalable analytics workloads on Amazon EC2 and Amazon EMR for complex, real-time analysis of large data sets. All while decreasing time to results and increasing business agility. Bryson Koehler, EVP & CIO of The Weather Company, will discuss architecture, technology choices, performance results and business benefits realized as part of their use of AWS services to host an exciting set of weather.com solutions and generate new revenue streams.
Weather impacts over 30% of the global GDP daily and is the source of vast amounts of data collection. The Weather Company is the leader in weather forecasting and is bringing the world's most accurate forecasting capabilities alive in a full suite of data APIs built fully on Infrastructure as a Service platforms, including AWS and next generation products like Basho Riak, Hadoop, and Dasein.
This session will discuss how the application of these technologies help keep people safe and helps businesses plan and become more profitable, thanks to the latest intersection of consumer behavior and weather forecasting and reporting.</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Sathish Gaddipati &ndash; VP of Enterprise Data with The Weather Company<br/>Raja Selvaraj &ndash; Manager, Data Systems Engineering with The Weather Company<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 2356);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(2356, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_2442" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=2442" class="openInPopup">
					
						<span class="abbreviation">BDT209 - </span>
					
					<span class="title">Trusted Analytics as a Service</span>
				</a>
				
					<span class="abstract">&nbsp;(Presented by Intel) This is the best of times and the worst of times for cloud services developers. At no other time in history has open access to data, open interfaces to data analytics, and open licensing of source code come together with scalable, cost-effective, cloud infrastructures. This is the good news.
The bad news is that enterprises are being left behind. Stymied by concerns of data protection and data governance, enterprises need proof that the services and solutions built on a cloud infrastructure comply with policies and practices they&rsquo;ve come to learn (not necessarily love). At its heart is the root of trust issue &ndash; how far down can I trust the cloud service, its infrastructure software, and the data that it analyzes? And how do I know my keys are safe? Join this session to learn how Intel has been enabling trusted analytics with cloud services secured top to bottom &ndash; from Apache Hadoop to Java, Xen, and Linux &ndash; without compromising security.</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Vin Sharma &ndash; Marketing Manager with Intel<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 2442);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(2442, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_2485" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=2485" class="openInPopup">
					
						<span class="abbreviation">BDT210 - </span>
					
					<span class="title">Adding Location and Geospatial Analytics to Big Data Analytics</span>
				</a>
				
					<span class="abstract">(Presented by Esri) When people analyze a problem, they often include location at the core of the analysis. Location and spatial context, combined with geographical knowledge, can make the biggest difference in understanding a problem and analyzing it in a more meaningful way.
In this session, we show how Amazon EMR can be used with location and geospatial analytics, and how the Amazon EMR API and the Python SDK were used to build tools that integrate Big Data and geospatial analysis. We also show powerful visualization options for displaying your results, using maps which can be shared in reports or distributed online and to mobile apps.</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Marwa Mabrouk &ndash; Cloud and Big Data Product Manager with ESRI<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 2485);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(2485, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_3035" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=3035" class="openInPopup">
					
						<span class="abbreviation">BDT211 - </span>
					
					<span class="title">Build Next Generation Real-time Applications with SAP HANA on the AWS Cloud</span>
				</a>
				
					<span class="abstract">(Presented by SAP) SAP HANA, available on the AWS Cloud, is an industry transforming in-memory platform, which has been adopted by many startups and ISVs, as well as traditional SAP enterprise customers. SAP HANA converges database and application platform capabilities in-memory to transform transactions, analytics, text analysis, predictive, and spatial processing so businesses can operate in real-time. Please join us to learn what SAP HANA can do for you! &nbsp;&nbsp;
Doug Turner, CEO of Mantis Technologies, and an early adopter of SAP HANA One on AWS, will present and share his experience migrating his Sentiment Analysis solution from MySQL to SAP HANA One. He will talk about following benefits that he achieved with this migration:

Dramatic simplification of his system architecture and landscape
System consolidation by moving from 23 MySQL instances to one SAP HANA One instance
Reduced overall AWS infrastructure cost as well as reduced admin effort and efficiency

We will conclude with an overview of all the key SAP HANA capabilities on the AWS Cloud like text analysis, predictive analytics, geospatial, data integration. We will round out the session with an in-depth view of what new HANA deployment options are available on the AWS Cloud like customers&rsquo; ability to bring their own licenses (BYOL) of SAP HANA to run on AWS in a variety of configurations ranging from 244GB up to 1.22TB.&nbsp;</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Doug Turner &ndash; CEO with Mantis Technologies<br/>Robert Groat &ndash; Chief Technology Officer with Smartronix<br/>Swen Conrad &ndash; Senior Director, Product Marketing, SAP HANA Cloud Solutions with SAP<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 3035);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(3035, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_3036" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=3036" class="openInPopup">
					
						<span class="abbreviation">BDT212 - </span>
					
					<span class="title">Real-world Cloud HPC at Scale, for Production Workloads</span>
				</a>
				
					<span class="abstract">Running high-performance scientific and engineering applications is challenging no matter where you do it. Join IT executives from HGST, Inc., a Western Digital Company, The Aerospace Corporation, Novartis, and Cycle Computing and learn how they have used the AWS cloud to deploy mission-critical HPC workloads.&nbsp; 
Cycle Computing leads the session on how organizations of any scale can run HPC workloads on AWS.&nbsp;&nbsp;HGST, Inc., discusses experiences using the cloud to create next-generation hard drives.&nbsp; The Aerospace Corporation provides perspectives on running MPI and other simulations, and offer insights into considerations like security while running rocket science on the cloud.&nbsp; Novartis Institutes for Biomedical Research talks about a scientific computing environment&nbsp;to do performance benchmark workloads and large HPC clusters, including a 30,000-core environment for research in the fight against cancer, using the Cancer Genome Atlas (TCGA).</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Jason Stowe &ndash; CEO with Cycle Computing<br/>Michael Steeves &ndash; Senior Systems Engineer with Novartis Institute for BioMedical Research, Inc.<br/>Steve Phillpott &ndash; CIO with HGST, Inc., a Western Digital Company<br/>Bill Williams &ndash; IT Executive with The Aerospace Corporation<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 3036);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(3036, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_1233" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=1233" class="openInPopup">
					
						<span class="abbreviation">BDT301 - </span>
					
					<span class="title">Scaling your Analytics with Amazon Elastic MapReduce</span>
				</a>
				
					<span class="abstract">Big data technologies let you work with any velocity, volume, or variety of data in a highly productive environment. Join the General Manager of Amazon EMR, Peter Sirota, to learn how to scale your analytics, use Hadoop with Amazon EMR, write queries with Hive, develop real world data flows with Pig, and understand the operational needs of a production data platform.</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Peter Sirota &ndash; Sr Manager, Software Development with Amazon Web Services<br/>Bob Harris &ndash; CTO with Channel 4 Television<br/>Eva Tse &ndash; Director of Big Data Platform with Netflix<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 1233);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(1233, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_1269" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=1269" class="openInPopup">
					
						<span class="abbreviation">BDT302 - </span>
					
					<span class="title">Deft Data at Netflix: Using Amazon S3 and Amazon Elastic MapReduce for Monitoring at Gigascale</span>
				</a>
				
					<span class="abstract">How does Netflix stay on top of the operations of its Internet service with millions of users and billions of metrics? With Atlas, its own massively distributed, large-scale monitoring system. Come learn how Netflix built Atlas with multiple processing pipelines using Amazon S3 and Amazon EMR to provide low-latency access to billions of metrics while supporting query-time aggregation along multiple dimensions.</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Roy Rapoport &ndash; Manager, Cloud Monitoring with Netflix, Inc<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 1269);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(1269, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_1621" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=1621" class="openInPopup">
					
						<span class="abbreviation">BDT303 - </span>
					
					<span class="title">Using AWS to Build a Graph-Based Product Recommendation System</span>
				</a>
				
					<span class="abstract">Magazine Luiza, one of the largest retail chains in Brazil, developed an in-house product recommendation system, built on top of a large knowledge Graph. AWS resources like Amazon EC2, Amazon SQS, Amazon ElastiCache and others made it possible for them to scale from a very small dataset to a huge Cassandra cluster. By improving their big data processing algorithms on their in-house solution built on AWS, they improved their conversion rates on revenue by more than 25 percent compared to market solutions they had used in the past.&nbsp;</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Andre Fatala &ndash; R&D Manager with Magazine Luiza - luizalabs<br/>Renato Pedigoni &ndash; Lead Software Engineer with Magazine Luiza - luizalabs<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 1621);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(1621, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_1709" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=1709" class="openInPopup">
					
						<span class="abbreviation">BDT304 - </span>
					
					<span class="title">Empowering Congress with Data-Driven Analytics</span>
				</a>
				
					<span class="abstract">MACPAC is a federal legislative branch agency tasked with reviewing state and federal Medicaid and &nbsp;Children's Health Insurance Program (CHIP) access and payment policies and making recommendations to Congress. By March 15 and again by June 15 each year, the agency produces a comprehensive report for Congress that compiles results from Medicaid and CHIP data sources for the 50 states and territories. The CIO of MACPAC wanted a secure, cost-effective, high performance platform that met their needs to crunch this large amount of health data. In this session, learn how MACPAC and 8KMiles helped set up the agency&rsquo;s Big Data/HPC analytics platform on AWS using SAS analytics software.</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Sri Vasireddy &ndash; Chief Cloud Officer with 8kMiles<br/>Mathew Chase &ndash; CIO with MACPAC.gov<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 1709);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(1709, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_1880" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=1880" class="openInPopup">
					
						<span class="abbreviation">BDT305 - </span>
					
					<span class="title">Building a Cloud Culture at Yelp</span>
				</a>
				
					<span class="abstract">Yelp is evolving from a purely hosted infrastructure environment to running many systems in AWS&mdash;paving the way for their growth to 108 million monthly visitors (source: Google Analytics). Embracing a cloud culture reduced reliability issues, sped up the pace of innovation, and helped them support dozens of data-intensive Yelp features, including search relevance, usage graphs, review highlights, spam filtering, and advertising optimizations. Today, Yelp runs 7+ TB hosted databases, 250+ GB compressed logs per day in Amazon S3, and hundreds of Amazon Elastic MapReduce jobs per day. In this session, Yelp engineers share the secrets of their success and show how they achieved big wins with Amazon EMR and open source libraries, policies around development, privacy, and testing.</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Jim Blomo &ndash; Engineering Manager - Data Mining with Yelp<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 1880);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(1880, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_1197" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=1197" class="openInPopup">
					
						<span class="abbreviation">BDT306 - </span>
					
					<span class="title">Data Science at Netflix with Amazon EMR</span>
				</a>
				
					<span class="abstract">A few years ago, Netflix had a fairly &quot;classic&quot; business intelligence tech stack. Things have definitely changed. Netflix is a heavy user of AWS for much of its ongoing operations, and&nbsp;Data Science & Engineering (DSE) is no exception. In this talk, we dive into the Netflix DSE architecture: what and why. Key topics include their use of&nbsp;Big Data technologies (Cassandra, Hadoop, Pig + Python, and Hive); their Amazon S3 central data hub; their multiple persistent Amazon EMR clusters; how they benefit from AWS elasticity; their data science-as-a-service approach, how they made a hybrid AWS/data center setup work well, their open-source&nbsp;Hadoop-related software, and more.</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Kurt Brown &ndash; Director, Data Platform with Netflix<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 1197);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(1197, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_1434" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=1434" class="openInPopup">
					
						<span class="abbreviation">BDT307 - </span>
					
					<span class="title">PetaMongo: A Petabyte Database for as Little as $200</span>
				</a>
				
					<span class="abstract">1,000,000,000,000,000 bytes. On demand. Online. Live. Big doesn't quite describe this data. Amazon Web Services makes it possible to construct highly elastic computing systems, and you can further increase cost efficiency by leveraging the Spot Pricing model for Amazon EC2. We showcase elasticity by demonstrating the creation and teardown of a petabyte-scale multiregion MongoDB NoSQL database cluster, using Amazon EC2 Spot Instances, for as little as $200 in total AWS costs. Oh and it offers up four&nbsp;million&nbsp;IOPS to storage via the power of PIOPS EBS.&nbsp; Christopher Biow, Principal Technologist &nbsp;at 10gen | MongoDB&nbsp;&nbsp;covers MongoDB best practices on AWS, so you can implement this NoSQL system (perhaps at a more pedestrian hundred-terabyte scale?) confidently in the cloud. You could build a massive enterprise warehouse, process a million human genomes, or collect a staggering number of cat GIFs. The possibilities are huMONGOus.</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Miles Ward &ndash; Sr. Manager, Solutions Architecture with Amazon Web Services<br/>Christopher Biow &ndash; Principal Technologist and Technical Director with MongoDB<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 1434);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(1434, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_1481" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=1481" class="openInPopup">
					
						<span class="abbreviation">BDT308 - </span>
					
					<span class="title">The Problem and Promise of Translational Genetics and a Step to the Clouded Solution of Scalable Clinical Whole Genome Sequencing</span>
				</a>
				
					<span class="abstract">Professors Wall and Tonellato of Harvard Medical School in collaboration with Beth Israel Deaconess Medical Center discuss the emerging area of clinical whole genome sequencing analysis and tools. They report on the use of&nbsp;Amazon EC2 and Spot Instances to achieve a robust &quot;clinical time&quot; processing solution and examine the barriers to and resolution of producing clinical-grade whole genome results in the cloud. They benchmark an AWS solution, called COSMOS, against local computing solutions and demonstrate the time and capacity gains conferred through the use of AWS.</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Jafar Shameem &ndash; Business Development Manager with Amazon Web Services<br/>Dennis Wall &ndash; Associate Professor with Stanford University<br/>Peter Tonellato with Harvard Medical School<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 1481);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(1481, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_1584" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=1584" class="openInPopup">
					
						<span class="abbreviation">BDT309 - </span>
					
					<span class="title">A Modern Framework for Amazon Elastic MapReduce</span>
				</a>
				
					<span class="abstract">If you've ever developed code for processing data, you know what a mess it can be&mdash;especially on Hadoop. You lack debugging tools, instant feedback, automated tests, and a sane deploy. Mortar has developed a modern framework for data processing on Hadoop and Amazon Elastic MapReduce. It is a free, open framework providing instant, step-by-step execution visibility, automated testing, reusable components, and one-button deployment.&nbsp; See how Mortar demonstrates this framework on Amazon EMR on a sample data set to solve a big data problem.</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Jeremy Karn &ndash; Engineer with Mortar Data<br/>K Young &ndash; CEO with Mortar Data<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 1584);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(1584, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_2180" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=2180" class="openInPopup">
					
						<span class="abbreviation">BDT310 - </span>
					
					<span class="title">Globus and Globus Genomics: How Science-as-a-Service is Accelerating Discovery</span>
				</a>
				
					<span class="abstract">In this talk, hear about two high-performant research services developed and operated by the Computation Institute at the University of Chicago running on AWS. Globus.org, a high-performance, reliable, robust file transfer service, has over 10,000 registered users who have moved over 25 petabytes of data using the service. The Globus service is operated entirely on AWS, leveraging Amazon EC2, Amazon EBS, Amazon S3, Amazon SES, Amazon SNS, etc. Globus Genomics is an end-to-end next-gen sequencing analysis service with state-of-art research data management capabilities. Globus Genomics uses Amazon EC2 for scaling out analysis, Amazon EBS for persistent storage, and Amazon S3 for archival storage.&nbsp;Attend this session to learn how to move data quickly at any scale as well as how to use genomic analysis tools and pipelines for next generation sequencers using Globus on AWS.
&nbsp;</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Ravi Madduri &ndash; Product Manager with University of Chicago<br/>Ian Foster &ndash; Director, Computation Institute with University of Chicago and Argonne National Laboratory<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 2180);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(2180, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_2042" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=2042" class="openInPopup">
					
						<span class="abbreviation">BDT311 - </span>
					
					<span class="title">New Launch: Supercharge Your Big Data Infrastructure with Amazon Kinesis: Learn to Build Real-time Streaming Big data Processing Applications</span>
				</a>
				
					<span class="abstract">This presentation provides an overview of the technical architecture of Kinesis, the new AWS service for real-time streaming big data ingestion and processing. This is done as part of describing how to implement a sample application that processes a Kinesis stream. The talk also describes how data ingested through Kinesis can be easily filtered, transformed, and uploaded into a variety of AWS storage services, such as S3 and Redshift.
&nbsp;</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">John Dunagan &ndash; Principal Algorithm Engineer with Amazon Web Services<br/>Ryan Waite &ndash; General Manager, Data Services with Amazon Web Services<br/>Marvin Theimer &ndash; Vice President, Distinguished Engineer with Amazon Web Services<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 2042);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(2042, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_1160" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=1160" class="openInPopup">
					
						<span class="abbreviation">BDT401 - </span>
					
					<span class="title">Using AWS to Build a Scalable Big Machine Data Management and Processing Service</span>
				</a>
				
					<span class="abstract">By turning the data center into an API, AWS has enabled Sumo Logic to build a very large scale IT operational analytics platform as a service at unprecedented scale and velocity. Based around Amazon EC2 and Amazon S3, the Sumo Logic system is ingesting many terabytes of unstructured log data a day while at the same time delivering real-time dashboards and supporting hundreds of thousands of queries against the collected data. When co-founder and CTO Christian Beedgen started Sumo Logic, it was obvious that the service would have to scale quickly and elastically, and AWS has been providing the perfect infrastructure for this endeavor from the start.&nbsp; 
In this talk, Christian dives into the core Sumo Logic architecture and explains which AWS services are making Sumo Logic possible. Based around an in-house developed automation and continuous deployment system, Sumo Logic is leveraging Amazon S3 in particular for large-scale data management and Amazon DynamoDB for cluster configuration management. By relying on automation, Sumo Logic is also able to perform sophisticated staging of new code for rapid deployment. Using the log-based instrumentation of the Sumo Logic codebase, Christian will dive into the performance characteristics achieved by the system today and share war stories about lessons learned along the way.</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Christian Beedgen &ndash; CTO & Co-Founder with Sumo Logic<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 1160);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(1160, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_1195" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=1195" class="openInPopup">
					
						<span class="abbreviation">BDT402 - </span>
					
					<span class="title">Finding New Sub-Atomic Particles on the AWS Cloud</span>
				</a>
				
					<span class="abstract">This session will describe how members of the US Large Hadron Collider (LHC) community have benchmarked the usage of Amazon Elastic Compute Cloud (Amazon EC2) resource to simulate events observed by experiments at the European Organization for Nuclear Research (CERN). &nbsp;Miron Livny from the University of Wisconsin-Madison who has been collaborating with the US-LHC community for more than a decade will detail the process for benchmarking&nbsp;high-throughput computing (HTC) applications running across multiple AWS regions using the open source HTCondor distributed computing software. &nbsp;The presentation will also outline the different ways that AWS and HTCondor can help meet the needs of compute intensive applications from other scientific disciplines.</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Jamie Kinney &ndash; Sr. Manager, Scientific and Research Computing with Amazon Web Services<br/>Miron Livny &ndash; Professor of Computer Science with University of Wisconsin<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 1195);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(1195, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	
		
		<div id="session_1270" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=1270" class="openInPopup">
					
						<span class="abbreviation">BDT404 - </span>
					
					<span class="title">Amazon Elastic MapReduce Deep Dive and Best Practices</span>
				</a>
				
					<span class="abstract">Amazon Elastic MapReduce is one of the largest Hadoop operators in the world. Since its launch four years ago, our customers have launched more than 5.5 million Hadoop clusters. In this talk, we introduce you to Amazon EMR design patterns such as using Amazon S3 instead of HDFS, taking advantage of both long and short-lived clusters and other Amazon EMR architectural patterns. We talk about how to scale your cluster up or down dynamically and introduce you to ways you can fine-tune your cluster. We also share best practices to keep your Amazon EMR cluster cost efficient.</span>
				
				
					<small class="length">1 Hour</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Parviz Deyhim &ndash; Solution Architect with Amazon Web Services<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
						
							
								<div class="sessionTimes">
									<a href="javascript:void(0);" onclick="showAvailSessions(this, 1270);" class="expandSessionImg"><span class="ww-icon ww-icon-carrot-e"></span>Scheduling Options</a>
									<ul class="availableSessions sessionTimeList"></ul>
								</div>
							
							
						
						
							<a href="javascript:void(0);" data-actiononlogin="toggleInterestOnLogin(1270, 'session')"  class="interest  openLoginDialog">
								
								<span class="ww-icon ww-icon-star"></span>Add to My Favorites
							</a>
						
						
					
				
				
			</div>
		</div>
	


	

<div id="downloadDocsDialog" title="Available Docs"></div>

	
<script type="text/javascript" charset="utf-8">
	
		//update search quantities
		updateSearchCount({
			attendee: '',
			session: '27',
			speaker: '393',
			exhibitor: '',
			file: '0'
		});
	
	$(function(){
		sessionTooltip();
		downloadDocDialogInit();
		ratingInit();
	});
</script>
